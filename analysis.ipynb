{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## machine-learners\n",
    "\n",
    "In this project we try out different models and feature sets to see what works best when trying to predict the sentiment of tweets about stocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in the data and organize it into train & test.\n",
    "train_examples = pd.read_csv('sent_train.csv').to_numpy()\n",
    "X_train = train_examples[:,0]\n",
    "y_train = train_examples[:,1].astype('int')\n",
    "\n",
    "test_examples = pd.read_csv('sent_valid.csv').to_numpy()\n",
    "X_test = test_examples[:,0]\n",
    "y_test = test_examples[:,1].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step I: Normalize\n",
    "# Step II: Tokenize\n",
    "# Step III: Get Features\n",
    "# Step IV: Train Model\n",
    "# Step V: Test to Get F1-Score & Other Measures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_one(texts):\n",
    "    tokenized_texts = []\n",
    "    for text in texts: \n",
    "        tokenized_texts.append(word_tokenize(re.sub(r'http\\S+', '', text.lower())))\n",
    "    return tokenized_texts\n",
    "\n",
    "token_funcs = [token_one]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns:\n",
    "#  (1) A map that maps a token to a spot in the feature array. \n",
    "def build_feat_dict(training_examples):\n",
    "    curr_pos = 0\n",
    "    features = {}\n",
    "\n",
    "    for example in training_examples:\n",
    "        for token in example:\n",
    "            if token not in features:\n",
    "                features[token] = curr_pos\n",
    "                curr_pos += 1\n",
    "    \n",
    "    return features\n",
    "\n",
    "#\n",
    "# To add a function to the feature\n",
    "#\n",
    "# Our baseline features are arrays with binary (0 or 1) values where we note whether or not a particular word has been seen. \n",
    "def featurize_one(X_train, X_test):\n",
    "    # Build the dictionary\n",
    "    feature_dict = build_feat_dict(X_train)\n",
    "\n",
    "    # Go through each example and record which words we've seen. \n",
    "    def get_seen_words(examples):\n",
    "        features = np.zeros((len(examples), len(feature_dict)))\n",
    "\n",
    "        for i in range(len(examples)):\n",
    "            tokens = examples[i]\n",
    "            for j in range(len(tokens)):\n",
    "                if tokens[j] in feature_dict:\n",
    "                    feature_idx = feature_dict[tokens[j]]\n",
    "                    features[i][feature_idx] = 1\n",
    "        return features\n",
    "\n",
    "    return get_seen_words(X_train), get_seen_words(X_test)\n",
    "\n",
    "feature_funcs = [featurize_one]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_mvb(X_train, X_test, y_train):\n",
    "    mnb = MultinomialNB()\n",
    "    return mnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "def classify_dt(X_train, X_test, y_train):\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    return clf.predict(X_test)\n",
    "\n",
    "pred_funcs = [classify_mvb, classify_dt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8036013400335008\n",
      "0.751675041876047\n"
     ]
    }
   ],
   "source": [
    "def get_score(token_func, feature_func, pred_func, X_train, y_train, X_test, y_test):\n",
    "    x_tr_tokens = token_func(X_train)\n",
    "    x_te_tokens = token_func(X_test)\n",
    "    x_tr_features, x_te_features = feature_func(x_tr_tokens, x_te_tokens)\n",
    "    y_pred = pred_func(x_tr_features, x_te_features, y_train)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "for token_func in token_funcs:\n",
    "    for feature_func in feature_funcs:\n",
    "        for pred_func in pred_funcs:\n",
    "            print(get_score(token_func, feature_func, pred_func, X_train, y_train, X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
